{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  ## <center> UDACITY DATA ANALYST NANODEGREE PROGRAM  </center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### <center> PROJECT 4:  </center>\n",
    "### <center> WRANGLE AND ANALYZE DATA REPORT </center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### <center> BY </center>\n",
    "### <center> ADETOLA HABEEB ADELASE </center>\n",
    "### <center> FEBURARY 4, 2022.<center> \n",
    "\n",
    "<div style=\"page-break-after: always;\"></div>\n",
    "    \n",
    "## Introduction \n",
    "This Wrangle and Analyze Data Project is part of Udacity's Nanodegree Data Analyst program. This project involved wrangling (and analyzing and visualizing) data from the Twitter user @ WeRateDogs, collected from different sources connected with the tweets. WeRateDogs is a Twitter account that rates photos of people's dogs in a humorous way. These ratings almost always have a denominator of 10.\n",
    "\n",
    "## Objectives\n",
    "The aim of this project is to “wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations”.\n",
    "    \n",
    "To achieve the aim of this project, there are some objectives that need to be fulfilled. Data Gathering: This  involves gathering the data to be used. We are going to gather data from a variety of sources. Accessing: assessing the data to gain better understanding of the data. Cleaning: this involves cleaning the data. The other steps involve Storing, analyzing,  visualizing, and reporting on the wrangled data. \n",
    "\n",
    "## Gathering Data\n",
    "There were three different data used for this project: twitter archive file, twitter API and an image tweet prediction file.\n",
    "\n",
    "    1. The twitter_archive_enchanced.csv was provided and downloaded manually from the Udacity classroom. The file contains specific variables for each tweet including tweet Id, name,  timestamp, text, number, and denominator ranking  etc.\n",
    "    \n",
    "    2. The tweet image predictions file was programmatically downloaded from Udacity 's servers using the Requests Python library. This file had the breed of dog, which was predicted based on the picture, using machine learning techniques.\n",
    "    \n",
    "    3. Twitter API and Python's Tweepy library was used to  gather each tweet's retweet count and favorite (\"like\") count at minimum.\n",
    "    \n",
    "  \n",
    "\n",
    "<div style=\"page-break-after: always;\"></div>\n",
    " \n",
    "\n",
    "## Accessing Data\n",
    "After gathering all three pieces of data,  the data was assessed visually and programmatically (pandas’ library) for quality and tidiness issues. At least **eight (8) quality issues** and **two (2) tidiness issues** were detected and documented.\n",
    "    \n",
    "**Quality Issues:**\n",
    "\n",
    "1. Timestamp is not of datetime format.\n",
    "\n",
    "2. Wrong Datatype: Columns tweet_id and in_reply_to_status_id should be in string and retweet_count and favorite_count should be integers,\n",
    "\n",
    "3. Invalid names and duplicate rows: Columns such as Name contain some invalid names.\n",
    "\n",
    "4. There are 59 null entries in the expanded_urls column. \n",
    "\n",
    "5. Delete retweets.\n",
    "\n",
    "6. Extracting ratings from the text of the tweet and be used to fill in the rating_numerator column.\n",
    "\n",
    "7. There are capitalized and lower cased names in the p1, p2, and p3 columns.\n",
    "\n",
    "8. Standardize dog ratings.\n",
    "    Extracting ratings from the text of the tweet and be used to fill in the rating_numerator column.\n",
    "\n",
    "9. Dropping columns not needed. (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, and retweeted_status_timestamp) The columns have too many null values in them.\n",
    "\n",
    "    \n",
    "**Tidiness Issues:**\n",
    "1. Merging the clean versions of df_twitter_archive, df_image_predictions, and df_tweet_json dataframes.\n",
    "\n",
    "2. Creating one column for the various dog types (doggo, floofer, pupper, puppo). \n",
    "- All  of the issues documented  above while assessing the data files were cleaned. I cleaned the data through the following means:\n",
    "    \n",
    "    \n",
    "**Define, Code and Test:**\n",
    "    \n",
    "    • Timestamp format is incorrect. The timestamp data type was changed  from object to datetime\n",
    "\n",
    "    • Data type of tweet_id and in_reply_to_status_id  should be string, not object. I changed the tweet_id  of all the data frame to string.\n",
    "\n",
    "    • Dog names such \"none\", \"a\", \"the\" and \"an\"  were dropped.\n",
    "\n",
    "    • The expanded_urls column that has null values was dropped. There are 59 total that we observed from the assessments.\n",
    "\n",
    "    • The ratings columns were standardize. \n",
    "    \n",
    "    • Retweet were deleted.\n",
    "\n",
    "    • Replaced all dog names in these columns with a lower-case letter.\n",
    "\n",
    "    • Extracted numerator ratings from the tweet text and to fill in the missing values in rating_numerator column by finding the pattern\n",
    "\n",
    "    • Dropped columns not needed\n",
    "\n",
    "    • Created one column for all the dog types.\n",
    "\n",
    "    • Merged the clean versions of the dataframes\n",
    "\n",
    "**Conclusion**\n",
    "The merged cleaned data frame was stored (dog_twitterpage), analyzed, and visualized. The project taught how that real-world data are rarely found in a single source and must be combined from multiple sources before any sort of analysis can be performed. It also aided my understanding of how tidiness and quality concerns can arise in data, as well as how to deal with them.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
